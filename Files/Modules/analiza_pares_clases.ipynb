{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80428cb-eeda-4d82-8736-60becb0fcbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analiza_pares_clases(X, y, clases_unicas):\n",
    "    \"\"\"\n",
    "    Analiza los pares de clases y evalúa con el perceptrón de sklearn.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    X : array-like\n",
    "        Datos de entrada.\n",
    "    y : array-like\n",
    "        Etiquetas correspondientes.\n",
    "    clases_unicas : array-like\n",
    "        Lista de todas las clases únicas en y.\n",
    "    \n",
    "    Devuelve:\n",
    "    ---------\n",
    "    None (muestra métricas y gráficas de las matrices de confusión seleccionadas).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parámetros del perceptrón\n",
    "    eta = 0.1  # Learning rate\n",
    "    t = 50  # Número de iteraciones\n",
    "\n",
    "    \n",
    "    pares_clases = list(itertools.combinations(clases_unicas, 2))  # Todos los pares posibles\n",
    "    resultados = []\n",
    "\n",
    "    for clase1, clase2 in pares_clases:\n",
    "        print(f\"Analizando clases {clase1} vs {clase2}...\")\n",
    "        \n",
    "        # Filtrar datos para las clases actuales\n",
    "        X_2C = X[(y == clase1) | (y == clase2)]\n",
    "        y_2C = y[(y == clase1) | (y == clase2)]\n",
    "        y_2C_binario = (y_2C == clase1).astype(int)  # Convertir a etiquetas binarias (0, 1)\n",
    "        \n",
    "        # Dividir en entrenamiento y prueba\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_2C, y_2C_binario, stratify=y_2C_binario, train_size=0.7)\n",
    "        \n",
    "        # ---- Perceptrón de sklearn ----\n",
    "        clf = Perceptron(max_iter=t, eta0=eta, random_state=42, shuffle=True)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        # Calcular métricas\n",
    "        exactitud = metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred, average=None).mean()\n",
    "        sensibilidad = metrics.recall_score(y_test, y_pred, average=None).mean()\n",
    "        conf_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # Almacenar resultados\n",
    "        resultados.append({\n",
    "            \"clases\": f\"{clase1}-{clase2}\",\n",
    "            \"exactitud\": exactitud,\n",
    "            \"precision\": precision,\n",
    "            \"sensibilidad\": sensibilidad,\n",
    "            \"conf_matrix\": conf_mat\n",
    "        })\n",
    "\n",
    "    # Ordenar los resultados por exactitud\n",
    "    resultados = sorted(resultados, key=lambda x: x[\"exactitud\"])\n",
    "    n = len(resultados)\n",
    "    \n",
    "    # Seleccionar pares con métricas bajas, promedio y altas\n",
    "    seleccionados = [\n",
    "        resultados[0],  # El par con exactitud más baja\n",
    "        resultados[1],  # El segundo más bajo\n",
    "        resultados[n//2 - 1],  # Cercano al promedio (primero)\n",
    "        resultados[n//2],  # Cercano al promedio (segundo)\n",
    "        resultados[-2],  # El segundo más alto\n",
    "        resultados[-1]   # El más alto\n",
    "    ]\n",
    "\n",
    "    # Mostrar matrices seleccionadas\n",
    "    for resultado in seleccionados:\n",
    "        print(f\"\\n--- Clases: {resultado['clases']} ---\")\n",
    "        print(f\"Exactitud: {resultado['exactitud']:.4f}\")\n",
    "        print(f\"Precisión: {resultado['precision']:.4f}\")\n",
    "        print(f\"Sensibilidad: {resultado['sensibilidad']:.4f}\")\n",
    "        \n",
    "        # Mostrar matriz de confusión\n",
    "        cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=resultado[\"conf_matrix\"], \n",
    "                                                     display_labels=resultado[\"clases\"].split(\"-\"))\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        cm_display.plot(ax=ax)\n",
    "        plt.title(f\"Matriz de confusión ({resultado['clases']})\")\n",
    "        plt.show()\n",
    "\n",
    "# Ejecución del análisis con tus datos\n",
    "clases_unicas = np.unique(yimage)  # Clases únicas de tu conjunto de datos\n",
    "analiza_pares_clases(Ximage, yimage, clases_unicas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77236778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analiza_pares_clases_entero(X, y, clases_unicas):\n",
    "    \"\"\"\n",
    "    Analiza los pares de clases y evalúa con el perceptrón de sklearn.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    X : array-like\n",
    "        Datos de entrada.\n",
    "    y : array-like\n",
    "        Etiquetas correspondientes.\n",
    "    clases_unicas : array-like\n",
    "        Lista de todas las clases únicas en y.\n",
    "    \n",
    "    Devuelve:\n",
    "    ---------\n",
    "    None (muestra métricas y gráficas de todas las matrices de confusión).\n",
    "    \"\"\"\n",
    "    # Parámetros del perceptrón\n",
    "    eta = 0.1  # Learning rate\n",
    "    t = 50  # Número de iteraciones\n",
    "    \n",
    "    pares_clases = list(itertools.combinations(clases_unicas, 2))  # Todos los pares posibles\n",
    "    resultados = []\n",
    "\n",
    "    for clase1, clase2 in pares_clases:\n",
    "        print(f\"Analizando clases {clase1} vs {clase2}...\")\n",
    "\n",
    "        # Filtrar datos para las clases actuales\n",
    "        X_2C = X[(y == clase1) | (y == clase2)]\n",
    "        y_2C = y[(y == clase1) | (y == clase2)]\n",
    "        y_2C_binario = (y_2C == clase1).astype(int)  # Convertir a etiquetas binarias (0, 1)\n",
    "\n",
    "        # Dividir en entrenamiento y prueba\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_2C, y_2C_binario, stratify=y_2C_binario, train_size=0.7)\n",
    "\n",
    "        # ---- Perceptrón de sklearn ----\n",
    "        clf = Perceptron(max_iter=t, eta0=eta, random_state=42, shuffle=True)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # Calcular métricas\n",
    "        exactitud = metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred, average=None).mean()\n",
    "        sensibilidad = metrics.recall_score(y_test, y_pred, average=None).mean()\n",
    "        conf_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # Almacenar resultados\n",
    "        resultados.append({\n",
    "            \"clases\": f\"{clase1}-{clase2}\",\n",
    "            \"exactitud\": exactitud,\n",
    "            \"precision\": precision,\n",
    "            \"sensibilidad\": sensibilidad,\n",
    "            \"conf_matrix\": conf_mat\n",
    "        })\n",
    "\n",
    "    # Mostrar métricas y matrices de confusión de todos los pares\n",
    "    for resultado in resultados:\n",
    "        print(f\"\\n--- Clases: {resultado['clases']} ---\")\n",
    "        print(f\"Exactitud: {resultado['exactitud']:.4f}\")\n",
    "        print(f\"Precisión: {resultado['precision']:.4f}\")\n",
    "        print(f\"Sensibilidad: {resultado['sensibilidad']:.4f}\")\n",
    "\n",
    "        # Mostrar matriz de confusión\n",
    "        cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=resultado[\"conf_matrix\"], \n",
    "                                                     display_labels=resultado[\"clases\"].split(\"-\"))\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        cm_display.plot(ax=ax)\n",
    "        plt.title(f\"Matriz de confusión ({resultado['clases']})\")\n",
    "        plt.show()\n",
    "\n",
    "# Ejecución del análisis con tus datos\n",
    "clases_unicas = np.unique(yimage)  # Clases únicas de tu conjunto de datos\n",
    "analiza_pares_clases_entero(Ximage, yimage, clases_unicas)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
